{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01603180",
      "metadata": {
        "id": "01603180"
      },
      "outputs": [],
      "source": [
        "import json \n",
        "import pandas as pd\n",
        "import random "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3762579a",
      "metadata": {
        "id": "3762579a"
      },
      "outputs": [],
      "source": [
        "# change path depending on dataset\n",
        "data_path = '/data/Eli5/Eli5_reranked/eli5_reranked.json'\n",
        "\n",
        "# output folder \n",
        "output_folder = '/contextretrieval/bi-encoder/eli5/splits/' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4fbc22d",
      "metadata": {
        "id": "c4fbc22d"
      },
      "outputs": [],
      "source": [
        "# read dataset \n",
        "with open(data_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "    \n",
        "data = pd.read_json(data, orient='records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62be5535",
      "metadata": {
        "id": "62be5535"
      },
      "outputs": [],
      "source": [
        "max_data_samples = 70000\n",
        "if len(data) < max_data_samples:\n",
        "    max_data_samples = len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e33f83b7",
      "metadata": {
        "id": "e33f83b7"
      },
      "source": [
        "### Test Passages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "213c002d",
      "metadata": {
        "id": "213c002d",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# group ids that share same passages\n",
        "relevant_docs_list = list(data.groupby('passages_text').apply(lambda x: list(x.id)))\n",
        "\n",
        "# remove ids with no duplicates\n",
        "relevant_docs_list = [x for x in relevant_docs_list if len(x) > 1]\n",
        "random.shuffle(relevant_docs_list)\n",
        "relevant_docs_list = relevant_docs_list[:int(max_data_samples*0.06)]\n",
        "\n",
        "passages_qids = [x[0] for x in relevant_docs_list]\n",
        "\n",
        "passage_idx = []\n",
        "for i in range(0, len(passages_qids)):\n",
        "    passage_idx.append(data.index[data['id'] == passages_qids[i]].tolist()[0])\n",
        "\n",
        "test_passages = data.iloc[passage_idx][['id', 'passages_text']]\n",
        "test_passages['relevant_ids'] = [x[1:] for x in relevant_docs_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1405099",
      "metadata": {
        "id": "a1405099"
      },
      "outputs": [],
      "source": [
        "test_passages.to_csv(output_folder + 'test_passages.csv', index=False) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c12b01fd",
      "metadata": {
        "id": "c12b01fd"
      },
      "source": [
        "### Test Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b42a5f",
      "metadata": {
        "id": "e1b42a5f"
      },
      "outputs": [],
      "source": [
        "# 15% of data for test\n",
        "max_corpus_size = int(max_data_samples*0.15) \n",
        "\n",
        "corpus_qids = [x[1:] for x in relevant_docs_list]\n",
        "corpus_qids = [qid for sublist in corpus_qids for qid in sublist]\n",
        "\n",
        "corpus_idx = []\n",
        "for i in range(0, len(corpus_qids)):\n",
        "    corpus_idx.append(data.index[data['id'] == corpus_qids[i]].tolist()[0])\n",
        "\n",
        "corpus = data.iloc[corpus_idx][['id', 'input']]\n",
        "\n",
        "# add random inputs to corpus \n",
        "other_inputs = data.drop(test_passages.index)\n",
        "other_inputs = data.drop(corpus.index).sample(frac=1)\n",
        "other_inputs = other_inputs.reset_index(drop=True)\n",
        "other_inputs = other_inputs[0:max(0, max_corpus_size-len(corpus))]\n",
        "other_inputs = other_inputs[['id', 'input']]\n",
        "\n",
        "test_corpus = pd.concat([corpus, other_inputs], axis=0).sample(frac=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28336e90",
      "metadata": {
        "id": "28336e90"
      },
      "outputs": [],
      "source": [
        "test_corpus.to_csv(output_folder + 'test_corpus.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b374fa62",
      "metadata": {
        "id": "b374fa62"
      },
      "source": [
        "### Train Pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ef7f2d1",
      "metadata": {
        "id": "1ef7f2d1"
      },
      "outputs": [],
      "source": [
        "# select data not used for test \n",
        "train_samples = data.drop(test_passages.index)\n",
        "train_samples = data.drop(test_corpus.index).sample(frac=1)\n",
        "train_samples = train_samples[:int(max_data_samples*0.85)] \n",
        "\n",
        "# select relevant columns for training \n",
        "train_pairs = train_samples[['id', 'input', 'passages_text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad0ff447",
      "metadata": {
        "id": "ad0ff447"
      },
      "outputs": [],
      "source": [
        "train_pairs.to_csv(output_folder + 'train_pairs.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "bi-encoder_splits.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
