{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "import json\n",
    "import ijson \n",
    "import argparse\n",
    "\n",
    "import random\n",
    "from argparse import Namespace\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "msmarco_path = '/ssd003/projects/aieng/conversational_ai/data/MSMARCO/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(msmarco_path + \"train.json\") as f:\n",
    "    train_stuff = json.load(f)\n",
    "    \n",
    "with open(msmarco_path+ \"valid.json\") as f:\n",
    "    valid_stuff = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distractor():\n",
    "    # get a distractor that is not the given answer and also not \"No Answer Present.\"\n",
    "    data = valid_stuff\n",
    "    all_keys = list(data['answers'].keys())\n",
    "    idx = random.choice(all_keys)\n",
    "    if data['answers'][idx][0] == 'No Answer Present.':\n",
    "        return get_distractor()\n",
    "    else:\n",
    "        return data['answers'][idx][0]\n",
    "    \n",
    "def create_marco_dataset(data):\n",
    "    all_keys = list(data['answers'].keys())\n",
    "    new_data = []\n",
    "    for key in tqdm(data['answers']):\n",
    "        data_chunk = {}\n",
    "        question = data['query'][key]\n",
    "        answers = data['answers'][key]\n",
    "        better_answers = data['wellFormedAnswers'][key]\n",
    "        contexts = data['passages'][key]\n",
    "        question_type = data['query_type'][key]\n",
    "\n",
    "        # if there exists a well-formed answer, use that one. Otherwise just use the answers provided.\n",
    "        if isinstance(better_answers, list):\n",
    "            new_answer = better_answers[0]\n",
    "        else:\n",
    "            new_answer = answers[0]\n",
    "\n",
    "        # if there's multiple answers and a person has not provided a correct good response, skip this question\n",
    "        if len(answers) > 1 and not isinstance(better_answers, list):\n",
    "            continue\n",
    "\n",
    "        # if the model can't extract the answer, at least be nice.\n",
    "        if new_answer == 'No Answer Present.':\n",
    "            new_answer = \"I'm sorry, I don't know.\"\n",
    "\n",
    "        data_chunk['context'] = contexts\n",
    "        data_chunk['query_type'] = question_type\n",
    "        data_chunk['utterances'] = []\n",
    "\n",
    "        if new_answer == \"I'm sorry, I don't know.\":\n",
    "            candidates = [get_distractor(), get_distractor(), new_answer]\n",
    "        else:\n",
    "            candidates = [\"I'm sorry, I don't know.\", get_distractor(), new_answer]\n",
    "        data_chunk['utterances'].append({\n",
    "            'history': [question],\n",
    "            'candidates': candidates\n",
    "        })\n",
    "\n",
    "        new_data.append(data_chunk)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marco_train = create_marco_dataset(train_stuff)\n",
    "with open('data/marco_train.json', 'w') as json_file:\n",
    "    json.dump(marco_train, json_file, indent=2)\n",
    "\n",
    "marco_valid = create_marco_dataset(valid_stuff)\n",
    "with open('data/marco_valid.json', 'w') as json_file:\n",
    "    json.dump(marco_valid, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/MSMARCO/marco_train_data.json', 'w') as json_file:\n",
    "    json.dump(marco_data['train'], json_file, indent=2)\n",
    "\n",
    "with open('data/MSMARCO/marco_valid_data.json', 'w') as json_file:\n",
    "    json.dump(marco_data['valid'], json_file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(obj, tokenizer):\n",
    "    for i in range(len(obj['context'])):\n",
    "        obj['context'][i]['passage_text'] = tokenizer.encode(obj['context'][i]['passage_text'])\n",
    "    for i in range(len(obj['utterances'])):\n",
    "        obj['utterances'][i]['history'] = [tokenizer.encode(x.lstrip(' ()_')) for x in obj['utterances'][i]['history']]\n",
    "        for j in range(len(obj['utterances'][i]['candidates'])):\n",
    "            obj['utterances'][i]['candidates'][j] = tokenizer.encode(obj['utterances'][i]['candidates'][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a772196ffd8453399a91ac2a12bf2fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/799698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(train_data))):\n",
    "    tokenize(train_data[i], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67cd3052f02e4719a981e666618a4ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(len(valid_data))):\n",
    "    tokenize(valid_data[i], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/MSMARCO/marco_train_tokenized.json', 'w') as json_file:\n",
    "    json.dump(train_data, json_file, indent=2)\n",
    "\n",
    "with open('data/MSMARCO/marco_valid_tokenized.json', 'w') as json_file:\n",
    "    json.dump(valid_data, json_file, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
