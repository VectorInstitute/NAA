{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla P100-PCIE-12GB\n"
     ]
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "import random\n",
    "import logging\n",
    "from pprint import pformat\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
    "\n",
    "from utils import *\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(device='cuda', force_answer=False, max_history=10, max_length=100, min_length=1, model_checkpoint_dir='/ssd003/home/shirleyw/ConversationalAI/dialomed_checkpoints/', model_checkpoint_file='/checkpoint/shirleyw/dialogpt_med_marco/checkpoint_epoch5_step587435.pth', no_sample=True, seed=39, temperature=0.7, top_k=100, top_p=0.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inference args\n",
    "args = Namespace(\n",
    "    # fill in where you have stored the checkpoint information and file\n",
    "    model_checkpoint_dir=\"/ssd003/home/shirleyw/ConversationalAI/dialomed_checkpoints/\",\n",
    "    model_checkpoint_file=\"/checkpoint/shirleyw/dialogpt_med_marco/checkpoint_epoch5_step587435.pth\",\n",
    "    max_history=10,\n",
    "    no_sample=True,\n",
    "    max_length=100,\n",
    "    min_length=1,\n",
    "    seed=39,\n",
    "    temperature=0.7,\n",
    "    top_k=100,\n",
    "    top_p=0.,  # I recommend setting this to 0 so its more likely to not say \"I don't know\"\n",
    "    device=(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    force_answer=False  # discard any \"I don't know\"s and take the next best prediction\n",
    ")\n",
    "\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TestingGPT2:Namespace(device='cuda', force_answer=False, max_history=10, max_length=100, min_length=1, model_checkpoint_dir='/ssd003/home/shirleyw/ConversationalAI/dialomed_checkpoints/', model_checkpoint_file='/checkpoint/shirleyw/dialogpt_med_marco/checkpoint_epoch5_step587435.pth', no_sample=True, seed=39, temperature=0.7, top_k=100, top_p=0.0)\n"
     ]
    }
   ],
   "source": [
    "# some basics\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"TestingGPT2\")\n",
    "logger.info(pformat(args))\n",
    "\n",
    "random.seed(args.seed)\n",
    "torch.random.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TestingGPT2:Get pretrained model and tokenizer\n",
      "Some weights of the model checkpoint at /checkpoint/shirleyw/dialogpt_med_marco/checkpoint_epoch5_step587435.pth were not used when initializing GPT2LMHeadModel: ['multiple_choice_head.summary.weight', 'multiple_choice_head.summary.bias']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Get pretrained model and tokenizer\")\n",
    "\n",
    "# Initializing GPT2 Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(args.model_checkpoint_dir)\n",
    "\n",
    "# Initializing pretrained model\n",
    "config = GPT2Config.from_json_file(args.model_checkpoint_dir + 'config.json')\n",
    "state_dict = torch.load(args.model_checkpoint_file)\n",
    "if 'model' in state_dict:\n",
    "    state_dict = state_dict['model']\n",
    "model = GPT2LMHeadModel.from_pretrained(args.model_checkpoint_file, config=config, state_dict=state_dict)\n",
    "del state_dict\n",
    "model.to(args.device)\n",
    "model.eval()\n",
    "\n",
    "# add our special tokens to the model\n",
    "add_special_tokens(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building datasets\n",
      "Loading Dataset\n",
      "Building inputs and labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100661it [00:43, 2330.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataloaders\n",
      "Valid Dataset Length: 60100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from DataLoader.dataloader import *\n",
    "\n",
    "dataargs = {\n",
    "    \"output_name\": \"dialomed_marco_epoch5_evalresults.json\",\n",
    "    \"log_dir\": \"/ssd003/home/shirleyw/ConversationalAI/dialomed_checkpoints/\",\n",
    "    \"checkpoint\": \"/checkpoint/shirleyw/dialogpt_med_marco/checkpoint_epoch5_step587435.pth\",\n",
    "    \"valid_dataset_path\": \"/ssd003/projects/aieng/conversational_ai/data/MSMARCO/marco_valid_tokenized.json\",\n",
    "    \"dataset_type\": \"marco\",\n",
    "    \"device\": \"cuda\",\n",
    "    \"max_len\": 1024,\n",
    "    \"valid_batch_size\": 1,\n",
    "    \"second_loss\": \"mc\"\n",
    "}\n",
    "dataargs = argparse.Namespace(**dataargs)\n",
    "\n",
    "valid_loader = get_validation_dataloader(dataargs, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_args = argparse.Namespace(\n",
    "    no_sample=True,\n",
    "    max_length=200,\n",
    "    min_length=1,\n",
    "    seed=39,\n",
    "    temperature=0.7,\n",
    "    top_k=100,\n",
    "    top_p=0.,\n",
    "    device=args.device,\n",
    "    force_answer=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, data in enumerate(valid_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_tokens = list(data['input_ids'][0, int(data['mc_labels'][0]), int(data['reply_start'][0]):])\n",
    "input_ids = list(data['input_ids'][0, int(data['mc_labels'][0]), :int(data['reply_start'][0])])\n",
    "token_type_ids = list(data['token_type_ids'][0, int(data['mc_labels'][0]), :int(data['reply_start'][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<bos> 1: a government-owned corporation (as a utility or railroad) engaged in a profit-making enterprise that may require the exercise of powers unique to government (as eminent domain) â€” called also government corporation, publicly held corporationExamples of corporation in a Sentence. 1  He works as a consultant for several large corporations. 2  a substantial corporation that showed that he was a sucker for all-you-can-eat buffets.McDonald's Corporation is one of the most recognizable corporations in the world. A corporation is a company or group of people authorized to act as a single entity (legally a person) and recognized as such in law. Early incorporated entities were established by charter (i.e. by an ad hoc act granted by a monarch or passed by a parliament or legislature).Corporation definition, an association of individuals, created by law or under authority of law, having a continuous existence independent of the existences of its members, and powers and liabilities distinct from those of its members. See more.Today, there is a growing community of more than 2,100 Certified B Corps from 50 countries and over 130 industries working together toward 1 unifying goal: to redefine success in business. Join the MovementA company is incorporated in a specific nation, often within the bounds of a smaller subset of that nation, such as a state or province. The corporation is then governed by the laws of incorporation in that state. A corporation may issue stock, either private or public, or may be classified as a non-stock corporation. If stock is issued, the corporation will usually be governed by its shareholders, either directly or indirectly. <speaker1>. what is a corporation?\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<speaker2> A corporation is a company or group of people authorized to act as a single entity and recognized as such in law. <eos>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(gt_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = sample_sequence_tokens(input_ids, token_type_ids, tokenizer, model, inference_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<speaker2> A corporation is an association of individuals, created by law or under authority of law.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['If your card is damaged, you will be required to pay the $20 replacement fee (debit or credit only). Damage can include use of stickers, hole punching, significant wear on the card within a short period of time, damage to the magnetic stripe or image. A new photo will be taken. Meal plan, library, building access, and athletic services will be active on your new card within 24 hours, or the Monday following a card replacement on Friday.\\n']\n"
     ]
    }
   ],
   "source": [
    "context = [\"\"\"If your card is damaged, you will be required to pay the $20 replacement fee (debit or credit only). Damage can include use of stickers, hole punching, significant wear on the card within a short period of time, damage to the magnetic stripe or image. A new photo will be taken. Meal plan, library, building access, and athletic services will be active on your new card within 24 hours, or the Monday following a card replacement on Friday.\n",
    "\"\"\"]\n",
    "           \n",
    "print(context)\n",
    "#My TCard is damaged, do I have to pay for a replacement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> My TCard is damaged, do I have to pay for a replacement?\n",
      "Out text: If your card is damaged, you will be required to pay the $20 replacement fee. If it is defective, you will be required to pay the $20 replacement fee within a short period of time. A new photo will be taken. Meal plan, library, building access, and athletic services will be active on your new card within 24 hours, or the Monday following a card replacement on Friday. A few tips on taking care of your TCard are as follows: Your TCard should be carried\n"
     ]
    }
   ],
   "source": [
    "# how many times do you want to ask questions\n",
    "num_times = 10\n",
    "\n",
    "for i in range(num_times):\n",
    "    raw_text = input(\">>> \")\n",
    "    while not raw_text:\n",
    "        print('Prompt should not be empty!')\n",
    "        raw_text = input(\">>> \")\n",
    "    history = [tokenizer.encode('<speaker1>' + raw_text)]\n",
    "    with torch.no_grad():\n",
    "        out_ids = sample_sequence(context, history, tokenizer, model, args)\n",
    "    out_text = tokenizer.decode(out_ids, skip_special_tokens=True)\n",
    "\n",
    "    print(\"Out text:\", out_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get F1 Score of prediction\n",
    "\n",
    "context = [\"\"\"If your card is damaged, you will be required to pay the $20 replacement fee (debit or credit only). Damage can include use of stickers, hole punching, significant wear on the card within a short period of time, damage to the magnetic stripe or image. A new photo will be taken. Meal plan, library, building access, and athletic services will be active on your new card within 24 hours, or the Monday following a card replacement on Friday.\n",
    "\"\"\"]\n",
    "context = [tokenizer.encode(x) for x in context]\n",
    "\n",
    "history = \"When will I get building access on my new card?\"\n",
    "history = [tokenizer.encode('<speaker1>' + history)]\n",
    "\n",
    "answer = \"You will get building access on your new card within 24 hours, or the Monday following a card replacement on Friday.\"\n",
    "answer = tokenizer.encode('<speaker2>' + answer)\n",
    "\n",
    "data = build_input_from_segments(context, history, answer, tokenizer, True, True)\n",
    "tokenizer.decode(data['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass through model\n",
    "input_ids = torch.Tensor(data['input_ids']).type(torch.LongTensor).to(args.device)\n",
    "lm_labels = torch.Tensor(data['lm_labels']).type(torch.LongTensor).to(args.device)\n",
    "token_type_ids = torch.Tensor(data['token_type_ids']).type(torch.LongTensor).to(args.device)\n",
    "start_index = torch.tensor(data['start_idx'])\n",
    "end_index = torch.tensor(data['mc_token_ids'])\n",
    "\n",
    "output = model(\n",
    "    input_ids, token_type_ids=token_type_ids\n",
    ")\n",
    "\n",
    "lm_logits = output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Answer: You will get building access on your new card within 24 hours, or the Monday following a card replacement on Friday. <eos>\n",
      "Prediction: You will get building access on your new card within 24 hours. or the Monday following a card replacement on Friday. <eos>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Actual Answer:\", tokenizer.decode(input_ids[start_index+1:end_index+1]))\n",
    "print(\"Rough Prediction:\", tokenizer.decode(torch.argmax(lm_logits[start_index:end_index], dim=1)))\n",
    "\n",
    "get_f1_score(input_ids, lm_logits, torch.tensor(data['start_idx']), torch.tensor(data['mc_token_ids']), tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that F1 Score is prone to spitting out a much higher number than what should be in our scenario. For the calculation of F1 Score, I'm just taking the argmax for each position in the logits, where as an actual language generation would generate the next token one at a time. Because of that, during response generation time, it's very common to predict an \"eos\" following a period, but that's not visible here when just taking the argmax, and what would have been predicted provided no eos is visible. So there's a higher chance of accurate tokens appearing here in the F1 Score than won't get predicted during actual response generation time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
